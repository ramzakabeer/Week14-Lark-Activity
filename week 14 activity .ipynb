{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7fafbc2",
   "metadata": {},
   "source": [
    "HELP International is an international humanitarian NGO that is committed to fighting poverty and providing the people of backward countries with basic amenities and relief during the time of disasters and natural calamities. After the recent project that included a lot of awareness drives and funding programmes, they have been able to raise around $ 10 million. The significant issues that come while making this decision are mostly related to choosing the countries that are in the direst need of aid. How will you help this NGO to make a correct decision based on socio-economic and health factors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc38bfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import xticks\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.cluster.hierarchy import cut_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "832b51aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Country-data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9ac23e360a66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Country-data.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Country-data.csv'"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"Country-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413ee4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6922a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4359fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eabd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d090c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cd8c82",
   "metadata": {},
   "source": [
    "# Data cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205178d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicates\n",
    "data.duplicated(subset = ['country'], keep = False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dcf74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6911b7",
   "metadata": {},
   "source": [
    "# Exploratory Data Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494a80de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairplot of numerical variables\n",
    "plt.figure(figsize = (4,4))\n",
    "sns.pairplot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44db9d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To look on the lowest 10 countries for each factor.\n",
    "fig, axs = plt.subplots(3,3,figsize = (20,15))\n",
    "\n",
    "# Child Mortality Rate : Death of children under 5 years of age per 1000 live births\n",
    "\n",
    "top10_child_mort = data[['country','child_mort']].sort_values('child_mort', ascending = False).head(10)\n",
    "plt1 = sns.barplot(x='country', y='child_mort', data= top10_child_mort, ax = axs[0,0])\n",
    "plt1.set(xlabel = '', ylabel= 'Child Mortality Rate')\n",
    "\n",
    "# Fertility Rate: The number of children that would be born to each woman if the current age-fertility rates remain the same\n",
    "top10_total_fer = data[['country','total_fer']].sort_values('total_fer', ascending = False).head(10)\n",
    "plt1 = sns.barplot(x='country', y='total_fer', data= top10_total_fer, ax = axs[0,1])\n",
    "plt1.set(xlabel = '', ylabel= 'Fertility Rate')\n",
    "\n",
    "# Life Expectancy: The average number of years a new born child would live if the current mortality patterns are to remain same\n",
    "\n",
    "bottom10_life_expec = data[['country','life_expec']].sort_values('life_expec', ascending = True).head(10)\n",
    "plt1 = sns.barplot(x='country', y='life_expec', data= bottom10_life_expec, ax = axs[0,2])\n",
    "plt1.set(xlabel = '', ylabel= 'Life Expectancy')\n",
    "\n",
    "# Health :Total health spending as %age of Total GDP.\n",
    "\n",
    "bottom10_health = data[['country','health']].sort_values('health', ascending = True).head(10)\n",
    "plt1 = sns.barplot(x='country', y='health', data= bottom10_health, ax = axs[1,0])\n",
    "plt1.set(xlabel = '', ylabel= 'Health')\n",
    "\n",
    "# The GDP per capita : Calculated as the Total GDP divided by the total population.\n",
    "\n",
    "bottom10_gdpp = data[['country','gdpp']].sort_values('gdpp', ascending = True).head(10)\n",
    "plt1 = sns.barplot(x='country', y='gdpp', data= bottom10_gdpp, ax = axs[1,1])\n",
    "plt1.set(xlabel = '', ylabel= 'GDP per capita')\n",
    "\n",
    "# Per capita Income : Net income per person\n",
    "\n",
    "bottom10_income = data[['country','income']].sort_values('income', ascending = True).head(10)\n",
    "plt1 = sns.barplot(x='country', y='income', data= bottom10_income, ax = axs[1,2])\n",
    "plt1.set(xlabel = '', ylabel= 'Per capita Income')\n",
    "\n",
    "# Inflation: The measurement of the annual growth rate of the Total GDP\n",
    "\n",
    "top10_inflation = data[['country','inflation']].sort_values('inflation', ascending = False).head(10)\n",
    "plt1 = sns.barplot(x='country', y='inflation', data= top10_inflation, ax = axs[2,0])\n",
    "plt1.set(xlabel = '', ylabel= 'Inflation')\n",
    "\n",
    "\n",
    "# Exports: Exports of goods and services. Given as %age of the Total GDP\n",
    "\n",
    "bottom10_exports = data[['country','exports']].sort_values('exports', ascending = True).head(10)\n",
    "plt1 = sns.barplot(x='country', y='exports', data= bottom10_exports, ax = axs[2,1])\n",
    "plt1.set(xlabel = '', ylabel= 'Exports')\n",
    "\n",
    "\n",
    "# Imports: Imports of goods and services. Given as %age of the Total GDP\n",
    "\n",
    "bottom10_imports = data[['country','imports']].sort_values('imports', ascending = True).head(10)\n",
    "plt1 = sns.barplot(x='country', y='imports', data= bottom10_imports, ax = axs[2,2])\n",
    "plt1.set(xlabel = '', ylabel= 'Imports')\n",
    "\n",
    "for ax in fig.axes:\n",
    "    plt.sca(ax)\n",
    "    plt.xticks(rotation = 90)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('eda')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbe18b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the correlation coefficients to see which variables are highly correlated\n",
    "plt.figure(figsize = (16, 10))\n",
    "sns.heatmap(data.corr(), annot = True, cmap=\"YlGnBu\")\n",
    "plt.savefig('corrplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f7b383",
   "metadata": {},
   "source": [
    "#high correlation exists between total_fer and child_mort, between gdpp and income,and between imports and exports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe06dc5",
   "metadata": {},
   "source": [
    "# Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ff8ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,3, figsize = (15,12))\n",
    "plt1 = sns.boxplot(data['child_mort'], ax = axs[0,0])\n",
    "plt2 = sns.boxplot(data['health'], ax = axs[0,1])\n",
    "plt3 = sns.boxplot(data['life_expec'], ax = axs[0,2])\n",
    "plt4 = sns.boxplot(data['total_fer'], ax = axs[1,0])\n",
    "plt5 = sns.boxplot(data['income'], ax = axs[1,1])\n",
    "plt6 = sns.boxplot(data['inflation'], ax = axs[1,2])\n",
    "plt7 = sns.boxplot(data['gdpp'], ax = axs[2,0])\n",
    "plt8 = sns.boxplot(data['imports'], ax = axs[2,1])\n",
    "plt9 = sns.boxplot(data['exports'], ax = axs[2,2])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e960841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving one copy of orignal data.\n",
    "data_help = data.copy()\n",
    "data_help.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a62a54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To identify backward countries based on socio economic and health factors.\n",
    "# We will cap the outliers to values accordingly for analysis.\n",
    "\n",
    "percentiles = data_help['child_mort'].quantile([0.05,0.95]).values\n",
    "data_help['child_mort'][data_help['child_mort'] <= percentiles[0]] = percentiles[0]\n",
    "data_help['child_mort'][data_help['child_mort'] >= percentiles[1]] = percentiles[1]\n",
    "\n",
    "percentiles = data_help['health'].quantile([0.05,0.95]).values\n",
    "data_help['health'][data_help['health'] <= percentiles[0]] = percentiles[0]\n",
    "data_help['health'][data_help['health'] >= percentiles[1]] = percentiles[1]\n",
    "\n",
    "percentiles = data_help['life_expec'].quantile([0.05,0.95]).values\n",
    "data_help['life_expec'][data_help['life_expec'] <= percentiles[0]] = percentiles[0]\n",
    "data_help['life_expec'][data_help['life_expec'] >= percentiles[1]] = percentiles[1]\n",
    "\n",
    "percentiles = data_help['total_fer'].quantile([0.05,0.95]).values\n",
    "data_help['total_fer'][data_help['total_fer'] <= percentiles[0]] = percentiles[0]\n",
    "data_help['total_fer'][data_help['total_fer'] >= percentiles[1]] = percentiles[1]\n",
    "\n",
    "percentiles = data_help['income'].quantile([0.05,0.95]).values\n",
    "data_help['income'][data_help['income'] <= percentiles[0]] = percentiles[0]\n",
    "data_help['income'][data_help['income'] >= percentiles[1]] = percentiles[1]\n",
    "\n",
    "percentiles = data_help['inflation'].quantile([0.05,0.95]).values\n",
    "data_help['inflation'][data_help['inflation'] <= percentiles[0]] = percentiles[0]\n",
    "data_help['inflation'][data_help['inflation'] >= percentiles[1]] = percentiles[1]\n",
    "\n",
    "percentiles = data_help['gdpp'].quantile([0.05,0.95]).values\n",
    "data_help['gdpp'][data_help['gdpp'] <= percentiles[0]] = percentiles[0]\n",
    "data_help['gdpp'][data_help['gdpp'] >= percentiles[1]] = percentiles[1]\n",
    "\n",
    "percentiles = data_help['imports'].quantile([0.05,0.95]).values\n",
    "data_help['imports'][data_help['imports'] <= percentiles[0]] = percentiles[0]\n",
    "data_help['imports'][data_help['imports'] >= percentiles[1]] = percentiles[1]\n",
    "\n",
    "percentiles = data_help['exports'].quantile([0.05,0.95]).values\n",
    "data_help['exports'][data_help['exports'] <= percentiles[0]] = percentiles[0]\n",
    "data_help['exports'][data_help['exports'] >= percentiles[1]] = percentiles[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f84e0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,3, figsize = (16,10))\n",
    "\n",
    "plt1 = sns.boxplot(data_help['child_mort'], ax = axs[0,0])\n",
    "plt2 = sns.boxplot(data_help['health'], ax = axs[0,1])\n",
    "plt3 = sns.boxplot(data_help['life_expec'], ax = axs[0,2])\n",
    "plt4 = sns.boxplot(data_help['total_fer'], ax = axs[1,0])\n",
    "plt5 = sns.boxplot(data_help['income'], ax = axs[1,1])\n",
    "plt6 = sns.boxplot(data_help['inflation'], ax = axs[1,2])\n",
    "plt7 = sns.boxplot(data_help['gdpp'], ax = axs[2,0])\n",
    "plt8 = sns.boxplot(data_help['imports'], ax = axs[2,1])\n",
    "plt9 = sns.boxplot(data_help['exports'], ax = axs[2,2])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a0545f",
   "metadata": {},
   "source": [
    "# Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f795d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import the StandardScaler()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a scaling object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create a list of the variables that you need to scale\n",
    "varlist = ['child_mort', 'exports', 'health', 'imports', 'income', 'inflation', 'life_expec', 'total_fer', 'gdpp']\n",
    "# Scale these variables using 'fit_transform'\n",
    "data_help[varlist] = scaler.fit_transform(data_help[varlist])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867252c9",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77990460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(svd_solver='randomized', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fc5f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_help.drop(['country'],axis=1)\n",
    "y = data_help['country']\n",
    "#Doing the PCA on the train data\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6ba862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing the PCA on the train data\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09df255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the principal components and try to make sense of them.\n",
    "#We will plot original features on the first 2 principal components as axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d53482",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a0098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = list(X.columns)\n",
    "pcs_df = pd.DataFrame({'PC1':pca.components_[0],'PC2':pca.components_[1], 'Feature':colnames})\n",
    "pcs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3952ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize = (10,8))\n",
    "plt.scatter(pcs_df.PC1, pcs_df.PC2)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "for i, txt in enumerate(pcs_df.Feature):\n",
    "    plt.annotate(txt, (pcs_df.PC1[i],pcs_df.PC2[i]))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91de6670",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c8cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cumulative variance against the number of components\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.savefig('pca_no')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43918b65",
   "metadata": {},
   "source": [
    "The figure shows 4 components are enough to describe 95% of the variance in the dataset\n",
    "We will choose 4 components for our modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149cbd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "pca_final = IncrementalPCA(n_components=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6709446",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = pca_final.fit_transform(X)\n",
    "df_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc87a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = pd.DataFrame(df_pca)\n",
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beec43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating correlation matrix for the principal components\n",
    "corrmat = np.corrcoef(df_pca.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3610ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation matrix\n",
    "%matplotlib inline\n",
    "plt.figure(figsize = (10,5))\n",
    "sns.heatmap(corrmat,annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376eed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dab4e3f",
   "metadata": {},
   "source": [
    "# Hopkins Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4964fe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from random import sample\n",
    "from numpy.random import uniform\n",
    "import numpy as np\n",
    "from math import isnan\n",
    " \n",
    "def hopkins(X):\n",
    "    d = X.shape[1]\n",
    "    #d = len(vars) # columns\n",
    "    n = len(X) # rows\n",
    "    m = int(0.1 * n) \n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(X.values)\n",
    " \n",
    "    rand_X = sample(range(0, n, 1), m)\n",
    " \n",
    "    ujd = []\n",
    "    wjd = []\n",
    "    for j in range(0, m):\n",
    "        u_dist, _ = nbrs.kneighbors(uniform(np.amin(X,axis=0),np.amax(X,axis=0),d).reshape(1, -1), 2, return_distance=True)\n",
    "        ujd.append(u_dist[0][1])\n",
    "        w_dist, _ = nbrs.kneighbors(X.iloc[rand_X[j]].values.reshape(1, -1), 2, return_distance=True)\n",
    "        wjd.append(w_dist[0][1])\n",
    " \n",
    "    H = sum(ujd) / (sum(ujd) + sum(wjd))\n",
    "    if isnan(H):\n",
    "        print(ujd, wjd)\n",
    "        H = 0\n",
    " \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c630c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hopkins(df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be88be8",
   "metadata": {},
   "source": [
    "# Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd5a84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "mergings = linkage(df_pca, method = \"complete\", metric='euclidean')\n",
    "dendrogram(mergings)\n",
    "plt.title('Dendrogram')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08063a5f",
   "metadata": {},
   "source": [
    "From the dedrogram it is evident that  n = 5 is most optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557800b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterCut = pd.Series(cut_tree(mergings, n_clusters = 5).reshape(-1,))\n",
    "df_pca_hc = pd.concat([df_pca, clusterCut], axis=1)\n",
    "df_pca_hc.columns = [\"PC1\",\"PC2\",\"PC3\",\"PC4\",\"ClusterID\"]\n",
    "df_pca_hc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9d6f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_cluster_hc = pd.concat([data_help['country'],df_pca_hc], axis=1, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, sort=None, copy=True)\n",
    "pca_cluster_hc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f866178",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_data_hc = pca_cluster_hc[['country','ClusterID']].merge(data, on = 'country')\n",
    "clustered_data_hc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65d8010",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_clusters_child_mort = pd.DataFrame(clustered_data_hc.groupby([\"ClusterID\"]).child_mort.mean())\n",
    "hc_clusters_exports = pd.DataFrame(clustered_data_hc.groupby([\"ClusterID\"]).exports.mean())\n",
    "hc_clusters_health = pd.DataFrame(clustered_data_hc.groupby([\"ClusterID\"]).health.mean())\n",
    "hc_clusters_imports = pd.DataFrame(clustered_data_hc.groupby([\"ClusterID\"]).imports.mean())\n",
    "hc_clusters_income = pd.DataFrame(clustered_data_hc.groupby([\"ClusterID\"]).income.mean())\n",
    "hc_clusters_inflation = pd.DataFrame(clustered_data_hc.groupby([\"ClusterID\"]).inflation.mean())\n",
    "hc_clusters_life_expec = pd.DataFrame(clustered_data_hc.groupby([\"ClusterID\"]).life_expec.mean())\n",
    "hc_clusters_total_fer = pd.DataFrame(clustered_data_hc.groupby([\"ClusterID\"]).total_fer.mean())\n",
    "hc_clusters_gdpp = pd.DataFrame(clustered_data_hc.groupby([\"ClusterID\"]).gdpp.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0def07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.Series(list(range(0,5))), hc_clusters_child_mort,hc_clusters_exports, hc_clusters_health, hc_clusters_imports,\n",
    "               hc_clusters_income, hc_clusters_inflation, hc_clusters_life_expec,hc_clusters_total_fer,hc_clusters_gdpp], axis=1)\n",
    "df.columns = [\"ClusterID\", \"child_mort_mean\", \"exports_mean\", \"health_mean\", \"imports_mean\", \"income_mean\", \"inflation_mean\",\n",
    "               \"life_expec_mean\", \"total_fer_mean\", \"gdpp_mean\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5997e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,3,figsize = (20,15))\n",
    "\n",
    "sns.barplot(x=df.ClusterID, y=df.child_mort_mean, ax = axs[0,0])\n",
    "sns.barplot(x=df.ClusterID, y=df.exports_mean, ax = axs[0,1])\n",
    "sns.barplot(x=df.ClusterID, y=df.health_mean, ax = axs[0,2])\n",
    "sns.barplot(x=df.ClusterID, y=df.imports_mean, ax = axs[1,0])\n",
    "sns.barplot(x=df.ClusterID, y=df.income_mean, ax = axs[1,1])\n",
    "sns.barplot(x=df.ClusterID, y=df.life_expec_mean, ax = axs[1,2])\n",
    "sns.barplot(x=df.ClusterID, y=df.inflation_mean, ax = axs[2,0])\n",
    "sns.barplot(x=df.ClusterID, y=df.total_fer_mean, ax = axs[2,1])\n",
    "sns.barplot(x=df.ClusterID, y=df.gdpp_mean, ax = axs[2,2])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6042763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_data_hc[clustered_data_hc.ClusterID == 0].country.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a84f342",
   "metadata": {},
   "source": [
    "This shows Cluster with ClusterID as 0, is the cluster of most backward country.\n",
    "the Countries on which we require to focus more are:\n",
    "\n",
    "Afghanistan,Benin,Botswana,Burkina Faso, Burundi,Cameroon, Central African Republic, Chad, Comoros,Congo, Dem. Rep., Cote d,Ivoire, Eritrea, Gabon, Gambia,\n",
    "Ghana, Guinea, Guinea-Bissau, Haiti, Iraq, Kenya,Kiribati, Lao, Lesotho, Liberia, Madagascar, Malawi,Mali, Micronesia, Fed. Sts., Mozambique, Namibia, Niger,\n",
    "Nigeria, Pakistan, Rwanda, Senegal, Sierra Leone,Solomon Islands, South Africa, Sudan, Tajikistan,Tanzania, Timor-Leste, Togo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
